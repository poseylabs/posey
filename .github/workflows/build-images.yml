name: Posey System Build

on:
  push:
    branches:
      - main
      - develop
  workflow_dispatch:
    inputs:
      service:
        description: Posey build'
        required: false
        type: string

env:
  DOCTL_VERSION: 1.92.1
  ENVIRONMENT: ${{ github.ref_name == 'main' && 'PRODUCTION' || 'STAGING' }}

jobs:
  build-posey:
    name: Build Posey (all)
    runs-on:
      group: posey-runners
    environment: PRODUCTION
    steps:
      - name: Debug runner information
        run: |
          echo "Runner name: $RUNNER_NAME"
          echo "Runner OS: $RUNNER_OS"
          echo "GitHub workspace: $GITHUB_WORKSPACE"
          echo "GitHub repository: $GITHUB_REPOSITORY"
          
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Debug Secret Availability
        run: |
          echo "Checking if DO_API_TOKEN secret is available..."
          if [ -n "${{ secrets.DO_API_TOKEN }}" ]; then
            echo "DO_API_TOKEN is available (value hidden for security)"
          else
            echo "DO_API_TOKEN appears to be empty or not available!"
          fi

      - name: Install doctl manually
        run: |
          # Download and install doctl
          cd /tmp
          curl -sL https://github.com/digitalocean/doctl/releases/download/v${{ env.DOCTL_VERSION }}/doctl-${{ env.DOCTL_VERSION }}-linux-arm64.tar.gz | tar -xzv
          sudo mv doctl /usr/local/bin/
          
          # Verify installation
          doctl version
          
          # Configure authentication
          doctl auth init -t ${{ secrets.DO_API_TOKEN }}

      - name: Login to DigitalOcean Container Registry
        run: |
          doctl registry login --expiry-seconds 3600
          
      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          
          # Remove unnecessary large directories
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          
          # Clean up apt cache
          sudo apt-get clean
          sudo apt-get autoremove -y
          
          # Clean Docker
          docker system prune -af --volumes
          
          echo "Disk space after cleanup:"
          df -h
          
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          version: v0.12.0
          
      - name: Docker Buildx Configuration
        run: |
          # Create a new buildx builder with multi-platform support
          docker buildx create --name multiplatform-builder --driver docker-container --use
          
          # Inspect the builder to verify multi-platform support
          docker buildx inspect --bootstrap
          
          # Show available platforms
          echo "Available platforms for building:"
          docker buildx inspect | grep "Platforms"
          
      - name: Create disk cleanup script
        run: |
          cat > /tmp/cleanup.sh << 'EOF'
          #!/bin/bash
          # Check if disk space is below threshold (15% free)
          DISK_FREE=$(df / | grep / | awk '{ print $4 }')
          THRESHOLD=$(($(df / | grep / | awk '{ print $2 }') * 15 / 100))
          
          if [ "$DISK_FREE" -lt "$THRESHOLD" ]; then
            echo "Disk space running low, cleaning up..."
            docker system prune -af --volumes
          fi
          EOF
          chmod +x /tmp/cleanup.sh
          
      - name: Prepare buildx cache directory
        run: |
          mkdir -p /tmp/.buildx-cache
          echo "{}" > /tmp/.buildx-cache/index.json
          echo "Created buildx cache directory with empty index"
          
      - name: Cache Docker layers
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-
            
      - name: Cache Playwright browsers
        id: playwright-cache
        uses: actions/cache@v3
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('services/voyager/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-playwright-
            
      - name: Pre-install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: |
          echo "Playwright cache not found, pre-installing browsers..."
          # Install playwright
          pip install playwright
          
          # Install only Chromium with deps - this is what the Voyager service needs
          python -m playwright install chromium --with-deps
          
          # Show what was installed
          echo "Browsers installed to: ~/.cache/ms-playwright"
          ls -la ~/.cache/ms-playwright
          
          # List all installed browsers
          python -m playwright install --help
          
      - name: Build Docker images
        run: |
          cd services
          
          # Set up periodic cleanup
          (while true; do /tmp/cleanup.sh; sleep 60; done) &
          CLEANUP_PID=$!
          
          # Build services one at a time
          SERVICES="auth supertokens voyager mcp agents cron"
          
          # If service input is specified, only build that one
          if [[ -n "${{ github.event.inputs.service }}" ]]; then
            SERVICES="${{ github.event.inputs.service }}"
          fi
          
          for SERVICE in $SERVICES; do
            echo "Building $SERVICE..."
            
            # Check if Dockerfile exists
            if [ ! -f "${SERVICE}/Dockerfile" ]; then
              echo "No Dockerfile found for ${SERVICE}, skipping build"
              continue
            fi
            
            # Special handling for voyager to speed up Playwright installation
            EXTRA_BUILD_ARGS=""
            if [ "${SERVICE}" == "voyager" ]; then
              echo "Adding special build args for Voyager service..."
              EXTRA_BUILD_ARGS="--build-arg PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1"
            fi
            
            # Set timeout based on service - some services need more build time
            TIMEOUT="15m"
            if [ "${SERVICE}" == "agents" ] || [ "${SERVICE}" == "voyager" ]; then
              TIMEOUT="25m"
              echo "Using extended timeout (25m) for ${SERVICE} due to potentially longer build time"
            fi
            
            # Use Docker Buildx for AMD64 builds with timeout
            echo "Starting build for ${SERVICE} with ${TIMEOUT} timeout..."
            timeout ${TIMEOUT} bash -c "DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain docker buildx build \
              --platform linux/amd64 \
              --build-arg BUILDKIT_INLINE_CACHE=1 \
              ${EXTRA_BUILD_ARGS} \
              --cache-from registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:latest \
              --cache-from registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${{ env.ENVIRONMENT }} \
              -t ${SERVICE} \
              -t registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:latest \
              -t registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${{ env.ENVIRONMENT }} \
              -t registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:$(echo $GITHUB_SHA | cut -c1-7) \
              -f ${SERVICE}/Dockerfile \
              --push \
              .." || {
                echo "⚠️ Error building $SERVICE, but continuing with other services"
              }
            
            # Run cleanup after each build
            /tmp/cleanup.sh
          done
          
          # Kill cleanup process
          kill $CLEANUP_PID || true
          
      - name: Build Data Services
        run: |
          cd data
          
          # Set up periodic cleanup
          (while true; do /tmp/cleanup.sh; sleep 60; done) &
          CLEANUP_PID=$!
          
          # Define data services to build
          DATA_SERVICES="postgres vector.db"
          
          for SERVICE in $DATA_SERVICES; do
            # Replace dots with dashes for Docker image name
            DOCKER_IMAGE_NAME=$(echo $SERVICE | tr '.' '-')
            
            echo "Building data service $SERVICE as $DOCKER_IMAGE_NAME..."
            
            if [ -f "${SERVICE}/Dockerfile" ]; then
              echo "Building $DOCKER_IMAGE_NAME with Docker Buildx..."
              timeout 15m bash -c "DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain docker buildx build \
                --platform linux/amd64 \
                --build-arg BUILDKIT_INLINE_CACHE=1 \
                --cache-from registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${DOCKER_IMAGE_NAME}:latest \
                --cache-from registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${DOCKER_IMAGE_NAME}:${{ env.ENVIRONMENT }} \
                -t ${DOCKER_IMAGE_NAME} \
                -t registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${DOCKER_IMAGE_NAME}:latest \
                -t registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${DOCKER_IMAGE_NAME}:${{ env.ENVIRONMENT }} \
                -t registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${DOCKER_IMAGE_NAME}:$(echo $GITHUB_SHA | cut -c1-7) \
                -f ${SERVICE}/Dockerfile \
                --push \
                .." || {
                  echo "⚠️ Error building $DOCKER_IMAGE_NAME, but continuing with other services"
                }
              
              # Run cleanup after each build
              /tmp/cleanup.sh
            else
              echo "No Dockerfile found for $SERVICE, skipping build"
            fi
          done
          
          # Kill cleanup process
          kill $CLEANUP_PID || true
          
      - name: Tag and push Docker images
        if: false # Skip this step since we're now tagging and pushing in the build step
        run: |
          echo "Skipping manual tagging and pushing step - images are already pushed by buildx"
          
      - name: Configure kubectl for ArgoCD sync
        run: |
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/arm64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          
          # Setup kubeconfig for DO Kubernetes
          doctl kubernetes cluster kubeconfig save ${{ secrets.DO_KUBERNETES_CLUSTER_ID }}
      
      - name: Install and configure Sealed Secrets
        run: |
          # Install kubeseal
          curl -L https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.26.0/kubeseal-0.26.0-linux-arm64.tar.gz -o kubeseal.tar.gz
          tar -xvzf kubeseal.tar.gz kubeseal
          chmod +x kubeseal
          sudo mv kubeseal /usr/local/bin/
          
          # Check if sealed-secrets namespace exists, if not create it
          if ! kubectl get namespace sealed-secrets &> /dev/null; then
            kubectl create namespace sealed-secrets
            
            # Add Helm repo
            helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets
            helm repo update
            
            # Install controller
            helm install sealed-secrets sealed-secrets/sealed-secrets -n sealed-secrets
            
            # Wait for controller to be ready
            kubectl -n sealed-secrets wait --for=condition=available deployment/sealed-secrets --timeout=90s
          fi
          
          # Create directory for certificate
          mkdir -p .sealed-secrets
          
          # Fetch certificate
          kubeseal --fetch-cert --controller-name=sealed-secrets --controller-namespace=sealed-secrets > .sealed-secrets/sealed-secrets-cert.pem
          
      - name: Generate Sealed Secrets for data services
        run: |
          cd data
          # Create temporary .env file from GitHub Secrets
          cat > .env << EOF
          # Postgres
          POSTGRES_USER=${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_DB=postgres
          POSTGRES_DB_POSEY=${{ secrets.POSTGRES_DB_POSEY }}
          POSTGRES_PORT=${{ secrets.POSTGRES_PORT || '3333' }}
          POSTGRES_HOST=${{ secrets.POSTGRES_HOST || 'posey-postgres' }}
          
          # Qdrant
          QDRANT_URL=${{ secrets.QDRANT_URL || 'http://posey-vector-db' }}
          QDRANT_PORT=${{ secrets.QDRANT_PORT || '1111' }}
          QDRANT_API_KEY=${{ secrets.QDRANT_API_KEY || '' }}
          EOF
          
          # Run the data sealed secrets generator
          cd ..
          export GITHUB_ACTIONS=true
          ./scripts/sealed-secrets/create-data-secrets.sh
          
      - name: Generate Sealed Secrets for application services
        run: |
          cd services
          # Create temporary .env file from GitHub Secrets
          cat > .env << EOF
          # Core Application Settings
          NODE_ENV=production
          ENVIRONMENT=${{ env.ENVIRONMENT }}
          
          # Service Ports & URLs
          AUTH_PORT=${{ secrets.AUTH_PORT || '9999' }}
          MCP_PORT=${{ secrets.MCP_PORT || '5050' }}
          VOYAGER_PORT=${{ secrets.VOYAGER_PORT || '7777' }}
          SUPER_TOKENS_PORT=${{ secrets.SUPER_TOKENS_PORT || '3567' }}
          
          # Auth Service
          AUTH_API_DOMAIN=${{ secrets.AUTH_API_DOMAIN || 'http://posey-auth' }}
          AUTH_BASE_URL=${{ secrets.AUTH_BASE_URL || 'http://posey-auth' }}
          UI_BASE_URL=${{ secrets.UI_BASE_URL || 'https://posey.ai' }}
          COOKIE_DOMAIN=${{ secrets.COOKIE_DOMAIN || '.posey.ai' }}
          
          # Cron Schedules
          MEMORY_PRUNING_SCHEDULE=${{ secrets.MEMORY_PRUNING_SCHEDULE || '"0 0 * * *"' }}
          MEMORY_CONSOLIDATION_SCHEDULE=${{ secrets.MEMORY_CONSOLIDATION_SCHEDULE || '"0 4 * * *"' }}
          CACHE_CLEANUP_SCHEDULE=${{ secrets.CACHE_CLEANUP_SCHEDULE || '"0 */6 * * *"' }}
          MEMORY_STATS_SCHEDULE=${{ secrets.MEMORY_STATS_SCHEDULE || '"0 1 * * *"' }}
          
          # AI Models
          EMBEDDING_MODEL=${{ secrets.EMBEDDING_MODEL || 'thenlper/gte-large' }}
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}
          
          # JWT
          JWT_SECRET_KEY=${{ secrets.JWT_SECRET_KEY }}
          
          # PostgreSQL
          POSTGRES_DB_POSEY=${{ secrets.POSTGRES_DB_POSEY || 'posey' }}
          POSTGRES_DB_SUPERTOKENS=${{ secrets.POSTGRES_DB_SUPERTOKENS || 'supertokens' }}
          POSTGRES_USER=${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_HOST=${{ secrets.POSTGRES_HOST || 'posey-postgres' }}
          POSTGRES_PORT=${{ secrets.POSTGRES_PORT || '3333' }}
          POSTGRES_DSN_POSEY=postgresql://${{ secrets.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@${{ secrets.POSTGRES_HOST || 'posey-postgres' }}:${{ secrets.POSTGRES_PORT || '3333' }}/${{ secrets.POSTGRES_DB_POSEY || 'posey' }}
          POSTGRES_DSN_SUPERTOKENS=postgresql://${{ secrets.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@${{ secrets.POSTGRES_HOST || 'posey-postgres' }}:${{ secrets.POSTGRES_PORT || '3333' }}/${{ secrets.POSTGRES_DB_SUPERTOKENS || 'supertokens' }}
          
          # Qdrant
          QDRANT_URL=${{ secrets.QDRANT_URL || 'http://posey-vector-db' }}
          QDRANT_PORT=${{ secrets.QDRANT_PORT || '1111' }}
          QDRANT_HOST=${{ secrets.QDRANT_URL || 'http://posey-vector-db' }}
          
          # SuperTokens
          SUPERTOKENS_CONNECTION_URI=${{ secrets.SUPERTOKENS_CONNECTION_URI || 'http://posey-supertokens:3567' }}
          SUPERTOKENS_API_KEY=${{ secrets.SUPERTOKENS_API_KEY }}
          
          # Other values
          VOYAGER_DOMAIN=${{ secrets.VOYAGER_DOMAIN || 'posey-voyager' }}
          EOF
          
          # Run the services sealed secrets generator
          cd ..
          export GITHUB_ACTIONS=true
          ./scripts/sealed-secrets/create-services-secrets.sh

      - name: Trigger ArgoCD sync
        if: success()
        continue-on-error: true  # Make this step optional so the workflow doesn't fail
        timeout-minutes: 5  # Increased timeout
        run: |
          # Install argocd CLI with better error handling
          echo "Downloading ArgoCD CLI..."
          mkdir -p /tmp/argocd-download
          cd /tmp/argocd-download
          
          # Try multiple times with different approaches
          if ! curl -sSL --retry 3 --retry-delay 5 -o argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-arm64; then
            echo "Direct download failed, trying with wget..."
            wget -q https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-arm64 -O argocd || {
              echo "Error downloading ArgoCD CLI. Trying specific version..."
              curl -sSL --retry 3 -o argocd https://github.com/argoproj/argo-cd/releases/download/v2.8.4/argocd-linux-arm64
            }
          fi
          
          chmod +x argocd
          sudo mv argocd /usr/local/bin/
          
          # Verify installation
          if ! argocd version --client; then
            echo "Failed to install ArgoCD CLI. Exiting."
            exit 1
          fi
          
          # Get ArgoCD password from Kubernetes secret
          ADMIN_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          
          # Login to ArgoCD with correct parameters
          echo "Logging in to ArgoCD at argo.posey.ai with grpc-web..."
          argocd login argo.posey.ai --username admin --password "$ADMIN_PASSWORD" --grpc-web
          
          # Get the short SHA for the latest commit
          SHORT_SHA=$(echo $GITHUB_SHA | cut -c1-7)
          echo "Using image tag: ${SHORT_SHA}"
          
          # Register applications if they don't exist
          echo "Checking if applications exist in ArgoCD..."
          
          # Define application details - include both services and data
          SERVICES="auth supertokens voyager mcp agents cron"
          DATA_SERVICES="postgres vector.db"
          
          if [[ -n "${{ github.event.inputs.service }}" ]]; then
            SERVICES="${{ github.event.inputs.service }}"
          fi
          
          # IMPORTANT: Force Kubernetes to use the SHA-tagged images
          echo "---------------------------------------------------------"
          echo "CRITICAL: Forcing deployments to use SHA-tagged images"
          echo "---------------------------------------------------------"
          
          NAMESPACE="${{ secrets.DO_REGISTRY_NAME }}"
          
          # Update service deployments with the SHA-tagged images
          for SERVICE in $SERVICES; do
            # Try updating the deployment image
            echo "Updating image for deployment/posey-${SERVICE} to use SHA tag ${SHORT_SHA}..."
            kubectl set image deployment/posey-${SERVICE} posey-${SERVICE}=registry.digitalocean.com/${NAMESPACE}/${SERVICE}:${SHORT_SHA} -n ${NAMESPACE} || true
            
            # Force restart the deployment
            echo "Force restarting deployment posey-${SERVICE}..."
            kubectl rollout restart deployment/posey-${SERVICE} -n ${NAMESPACE} || true
          done
          
          # Update data service deployments/statefulsets
          for SERVICE in $DATA_SERVICES; do
            # Replace dots with dashes for app name
            APP_NAME=$(echo $SERVICE | tr '.' '-')
            
            # Try updating the statefulset or deployment
            # First try statefulset
            echo "Attempting to update statefulset/posey-${APP_NAME} to use SHA tag ${SHORT_SHA}..."
            kubectl set image statefulset/posey-${APP_NAME} posey-${APP_NAME}=registry.digitalocean.com/${NAMESPACE}/${APP_NAME}:${SHORT_SHA} -n ${NAMESPACE} || true
            kubectl rollout restart statefulset/posey-${APP_NAME} -n ${NAMESPACE} || true
            
            # Then try deployment (in case it's a deployment instead)
            echo "Attempting to update deployment/posey-${APP_NAME} to use SHA tag ${SHORT_SHA}..."
            kubectl set image deployment/posey-${APP_NAME} posey-${APP_NAME}=registry.digitalocean.com/${NAMESPACE}/${APP_NAME}:${SHORT_SHA} -n ${NAMESPACE} || true
            kubectl rollout restart deployment/posey-${APP_NAME} -n ${NAMESPACE} || true
            
            # Try without posey- prefix (some services might not have it)
            echo "Attempting to update without posey- prefix..."
            kubectl set image deployment/${APP_NAME} ${APP_NAME}=registry.digitalocean.com/${NAMESPACE}/${APP_NAME}:${SHORT_SHA} -n ${NAMESPACE} || true
            kubectl rollout restart deployment/${APP_NAME} -n ${NAMESPACE} || true
            kubectl set image statefulset/${APP_NAME} ${APP_NAME}=registry.digitalocean.com/${NAMESPACE}/${APP_NAME}:${SHORT_SHA} -n ${NAMESPACE} || true
            kubectl rollout restart statefulset/${APP_NAME} -n ${NAMESPACE} || true
          done
          
          # Now proceed with normal ArgoCD sync
          echo "---------------------------------------------------------"
          echo "Proceeding with normal ArgoCD sync"
          echo "---------------------------------------------------------"
          
          # Create and sync service applications 
          for SERVICE in $SERVICES; do
            if ! argocd app get posey-$SERVICE &>/dev/null; then
              echo "Creating application posey-$SERVICE in ArgoCD..."
              argocd app create posey-$SERVICE \
                --repo https://github.com/${{ github.repository }}.git \
                --path k8s/$SERVICE \
                --dest-server https://kubernetes.default.svc \
                --dest-namespace ${{ secrets.DO_REGISTRY_NAME }} \
                --directory-recurse || true
            fi
            
            # Sync the application
            echo "Syncing posey-${SERVICE}..."
            argocd app sync posey-$SERVICE --timeout 120 --prune || true
          done
          
          # Create and sync data service applications
          for SERVICE in $DATA_SERVICES; do
            # Replace dots with dashes for app name
            APP_NAME=$(echo $SERVICE | tr '.' '-')
            
            # For vector.db, use vector-db in the k8s path
            K8S_PATH="k8s"
            if [ "${SERVICE}" == "vector.db" ]; then
              K8S_PATH="data/${SERVICE}/k8s"  # Use the data path for vector.db
            elif [ "${SERVICE}" == "postgres" ]; then
              K8S_PATH="data/${SERVICE}/k8s"  # Use the data path for postgres
            fi
            
            if ! argocd app get posey-$APP_NAME &>/dev/null; then
              echo "Creating data application posey-$APP_NAME in ArgoCD..."
              argocd app create posey-$APP_NAME \
                --repo https://github.com/${{ github.repository }}.git \
                --path ${K8S_PATH} \
                --dest-server https://kubernetes.default.svc \
                --dest-namespace ${{ secrets.DO_REGISTRY_NAME }} \
                --directory-recurse || true
            fi
            
            # Sync the application
            echo "Syncing posey-${APP_NAME}..."
            argocd app sync posey-$APP_NAME --timeout 120 --prune || true
          done
          
          echo "ArgoCD sync completed or attempted for all services"
          
          # Apply configurations directly with kubectl as a fallback
          echo "---------------------------------------------------"
          echo "Also applying with kubectl to ensure updates..."
          cd $GITHUB_WORKSPACE
          
          # Define namespace and services
          NAMESPACE="${{ secrets.DO_REGISTRY_NAME }}"
          echo "Using namespace: ${NAMESPACE}"
          
          # Fix PVC issues - check existing PVC sizes to avoid downsizing attempts
          echo "---------------------------------------------------"
          echo "Checking PVC sizes to avoid downsizing errors..."
          
          # Get current PVC sizes
          kubectl get pvc -n ${NAMESPACE} -o custom-columns=NAME:.metadata.name,SIZE:.spec.resources.requests.storage || true
          
          # Detect and fix potential PVC downsizing issues in YAML files
          echo "Checking for potential PVC downsizing issues in manifest files..."
          
          # Function to check if a PVC already exists with larger size
          check_pvc_downsizing() {
            PVC_NAME=$1
            FILE_PATH=$2
            
            # Get the size from the current PVC
            CURRENT_SIZE=$(kubectl get pvc ${PVC_NAME} -n ${NAMESPACE} -o jsonpath='{.spec.resources.requests.storage}' 2>/dev/null)
            if [ -z "$CURRENT_SIZE" ]; then
              echo "PVC ${PVC_NAME} does not exist yet, no size conflict"
              return 0
            fi
            
            # Get the size from the YAML file
            if [ -f "${FILE_PATH}" ]; then
              # This extracts the storage size from a Kubernetes YAML file
              FILE_SIZE=$(grep -A5 "storage:" "${FILE_PATH}" | grep -oP '(?<=storage: )[0-9]+[GM]i' | head -1)
              if [ -z "$FILE_SIZE" ]; then
                echo "Could not find storage size in ${FILE_PATH}"
                return 0
              fi
              
              echo "PVC ${PVC_NAME}: Current=${CURRENT_SIZE}, File=${FILE_SIZE}"
              
              # Convert sizes to bytes for comparison (simplified approach)
              CURRENT_NUM=$(echo ${CURRENT_SIZE} | grep -oP '[0-9]+')
              FILE_NUM=$(echo ${FILE_SIZE} | grep -oP '[0-9]+')
              
              CURRENT_UNIT=$(echo ${CURRENT_SIZE} | grep -oP '[GMK]i')
              FILE_UNIT=$(echo ${FILE_SIZE} | grep -oP '[GMK]i')
              
              # Simple comparison - not perfect but catches obvious issues
              if [[ "$CURRENT_UNIT" == "Gi" && "$FILE_UNIT" == "Mi" ]]; then
                echo "⚠️ Warning: PVC ${PVC_NAME} would be downsized from ${CURRENT_SIZE} to ${FILE_SIZE}"
                echo "Temporarily skipping file ${FILE_PATH} to prevent errors"
                # Rename the file temporarily to skip it during apply
                mv "${FILE_PATH}" "${FILE_PATH}.skip"
                return 1
              elif [[ "$CURRENT_UNIT" == "$FILE_UNIT" && $CURRENT_NUM -gt $FILE_NUM ]]; then
                echo "⚠️ Warning: PVC ${PVC_NAME} would be downsized from ${CURRENT_SIZE} to ${FILE_SIZE}"
                echo "Temporarily skipping file ${FILE_PATH} to prevent errors"
                # Rename the file temporarily to skip it during apply
                mv "${FILE_PATH}" "${FILE_PATH}.skip"
                return 1
              fi
            fi
            return 0
          }
          
          # Check common PVC files
          check_pvc_downsizing "agents-data-pvc" "services/shared/k8s/agents-data-pvc.yaml" || true
          check_pvc_downsizing "agents-models-pvc" "services/shared/k8s/agents-models-pvc.yaml" || true
          check_pvc_downsizing "voyager-cache-pvc" "services/shared/k8s/voyager-cache-pvc.yaml" || true
          check_pvc_downsizing "voyager-data-pvc" "services/shared/k8s/voyager-data-pvc.yaml" || true
          check_pvc_downsizing "postgres-pvc" "data/postgres/k8s/postgres-storage.yaml" || true
          
          # Apply configurations with kubectl using the central k8s directory
          echo "Applying configurations directly with kubectl using kustomize..."
          kubectl get namespace $NAMESPACE || kubectl create namespace $NAMESPACE
          
          # Apply shared resources from the central k8s structure
          if [ -d "k8s/shared" ]; then
            echo "Applying shared resources from central k8s directory..."
            kubectl apply -k k8s/shared -n $NAMESPACE || true
          fi
          
          # Apply service resources using kustomize
          for SERVICE in $SERVICES; do
            if [ -d "k8s/${SERVICE}" ]; then
              echo "Applying resources for ${SERVICE} from central k8s directory..."
              kubectl apply -k k8s/${SERVICE} -n $NAMESPACE || true
            else
              echo "No central k8s directory for ${SERVICE}, trying service-specific path..."
              kubectl apply -f services/${SERVICE}/k8s/ -n $NAMESPACE || true
            fi
          done
          
          # Apply data service resources
          for SERVICE in $DATA_SERVICES; do
            APP_NAME=$(echo $SERVICE | tr '.' '-')
            # Try central k8s structure first
            if [ -d "k8s/${APP_NAME}" ]; then
              echo "Applying resources for ${APP_NAME} from central k8s directory..."
              kubectl apply -k k8s/${APP_NAME} -n $NAMESPACE || true
            else
              echo "No central k8s directory for ${APP_NAME}, trying data-specific path..."
              kubectl apply -f data/${SERVICE}/k8s/ -n $NAMESPACE || true
            fi
          done
          
          # Verify pod status
          echo "---------------------------------------------------"
          echo "Current pod status:"
          kubectl get pods -n ${NAMESPACE}
          
          echo "---------------------------------------------------"
          echo "Deployment rollout status:"
          for SERVICE in $SERVICES; do
            echo "Checking rollout status for deployment/posey-${SERVICE}..."
            kubectl rollout status deployment/posey-${SERVICE} -n ${NAMESPACE} --timeout=30s || true
          done
          
          # Restore any renamed PVC files
          echo "---------------------------------------------------"
          echo "Restoring any temporarily renamed PVC files..."
          find . -name "*.yaml.skip" -exec bash -c 'mv "$1" "${1%.skip}"' bash {} \; || true
          
          echo "Deployment initiated. All services should be updated in Kubernetes."

      - name: Create minimal .env file for CI
        run: |
          cat > services/.env << EOF
          # This is an auto-generated .env file for CI deployment
          ENVIRONMENT=${{ env.ENVIRONMENT }}
          
          # DigitalOcean configuration
          DO_REGISTRY_NAME=${{ secrets.DO_REGISTRY_NAME }}
          DO_KUBERNETES_CLUSTER_ID=${{ secrets.DO_KUBERNETES_CLUSTER_ID }}
          
          # Add other CI-specific environment variables here
          NODE_ENV=production
          LOG_LEVEL=info
          
          # Add any additional secrets that deployment scripts need
          QDRANT_HOST=${{ secrets.QDRANT_HOST || 'qdrant.default.svc.cluster.local' }}
          QDRANT_PORT=${{ secrets.QDRANT_PORT || '6333' }}
          POSTGRES_HOST=${{ secrets.POSTGRES_HOST || 'postgres.default.svc.cluster.local' }}
          POSTGRES_PORT=${{ secrets.POSTGRES_PORT || '5432' }}
          EOF
          
          echo "Created CI environment file with necessary deployment variables" 