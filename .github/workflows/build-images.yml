name: Build Posey System

on:
  push:
    branches:
      - main
      - develop
  workflow_dispatch:
    inputs:
      service:
        description: Posey build'
        required: false
        type: string

env:
  DOCTL_VERSION: 1.92.1
  ENVIRONMENT: ${{ github.ref_name == 'main' && 'PRODUCTION' || 'STAGING' }}

jobs:
  build-posey:
    name: Build Posey (all)
    runs-on:
      group: posey-runners
    environment: PRODUCTION
    steps:
      - name: Debug runner information
        run: |
          echo "Runner name: $RUNNER_NAME"
          echo "Runner OS: $RUNNER_OS"
          echo "GitHub workspace: $GITHUB_WORKSPACE"
          echo "GitHub repository: $GITHUB_REPOSITORY"
          
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Enable Corepack
        run: |
          corepack enable
          yarn --version

      - name: Install dependencies
        run: |
          cd services
          yarn install

      - name: Debug Secret Availability
        run: |
          echo "Checking if DO_API_TOKEN secret is available..."
          if [ -n "${{ secrets.DO_API_TOKEN }}" ]; then
            echo "DO_API_TOKEN is available (value hidden for security)"
          else
            echo "DO_API_TOKEN appears to be empty or not available!"
          fi

      - name: Install doctl manually
        run: |
          # Download and install doctl
          cd /tmp
          curl -sL https://github.com/digitalocean/doctl/releases/download/v${{ env.DOCTL_VERSION }}/doctl-${{ env.DOCTL_VERSION }}-linux-arm64.tar.gz | tar -xzv
          sudo mv doctl /usr/local/bin/
          
          # Verify installation
          doctl version
          
          # Configure authentication
          doctl auth init -t ${{ secrets.DO_API_TOKEN }}

      - name: Login to DigitalOcean Container Registry
        run: |
          doctl registry login --expiry-seconds 3600
          
      - name: Free up disk space
        run: |
          echo "Disk space before cleanup:"
          df -h
          
          # Remove unnecessary large directories
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          
          # Clean up apt cache
          sudo apt-get clean
          sudo apt-get autoremove -y
          
          # Clean Docker
          docker system prune -af --volumes
          
          echo "Disk space after cleanup:"
          df -h
          
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          version: v0.12.0
          
      - name: Create disk cleanup script
        run: |
          cat > /tmp/cleanup.sh << 'EOF'
          #!/bin/bash
          # Check if disk space is below threshold (15% free)
          DISK_FREE=$(df / | grep / | awk '{ print $4 }')
          THRESHOLD=$(($(df / | grep / | awk '{ print $2 }') * 15 / 100))
          
          if [ "$DISK_FREE" -lt "$THRESHOLD" ]; then
            echo "Disk space running low, cleaning up..."
            docker system prune -af --volumes
          fi
          EOF
          chmod +x /tmp/cleanup.sh
          
      - name: Prepare buildx cache directory
        run: |
          mkdir -p /tmp/.buildx-cache
          echo "{}" > /tmp/.buildx-cache/index.json
          echo "Created buildx cache directory with empty index"
          
      - name: Cache Docker layers
        uses: actions/cache@v3
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-
            
      - name: Set up Python dependencies cache
        id: python-cache
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Cache Python wheels
        id: wheel-cache
        uses: actions/cache@v3
        with:
          path: services/agents/.wheels
          key: ${{ runner.os }}-wheels-${{ hashFiles('services/agents/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-wheels-

      - name: Setup model cache directories
        run: |
          mkdir -p ~/.cache/huggingface
          mkdir -p ~/.cache/torch
          mkdir -p services/agents/.wheels
          
      - name: Cache HuggingFace models
        id: hf-cache
        uses: actions/cache@v3
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-huggingface-${{ hashFiles('services/agents/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-huggingface-
            
      - name: Cache PyTorch models
        id: torch-cache
        uses: actions/cache@v3
        with:
          path: ~/.cache/torch
          key: ${{ runner.os }}-torch-${{ hashFiles('services/agents/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-torch-
      
      - name: Build Docker images
        run: |
          cd services
          
          # Set up periodic cleanup
          (while true; do /tmp/cleanup.sh; sleep 60; done) &
          CLEANUP_PID=$!
          
          # Build services one at a time
          SERVICES="auth supertokens voyager mcp agents cron"
          
          # If service input is specified, only build that one
          if [[ -n "${{ github.event.inputs.service }}" ]]; then
            SERVICES="${{ github.event.inputs.service }}"
          fi
          
          for SERVICE in $SERVICES; do
            echo "Building $SERVICE..."
            
            # Use direct Docker build for all services (bypassing yarn build completely)
            echo "Building $SERVICE directly with Docker..."
            DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain docker build \
              --build-arg BUILDKIT_INLINE_CACHE=1 \
              --cache-from registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:latest \
              --cache-from registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${{ env.ENVIRONMENT }} \
              --platform linux/arm64 \
              -t ${SERVICE} \
              -f ${SERVICE}/Dockerfile \
              ./${SERVICE} || {
                echo "⚠️ Warning: Error building $SERVICE with direct Docker command, but continuing"
              }
            
            # Run cleanup after each build
            /tmp/cleanup.sh
          done
          
          # Kill cleanup process
          kill $CLEANUP_PID || true
          
      - name: Build Data Services
        run: |
          cd data
          
          # Set up periodic cleanup
          (while true; do /tmp/cleanup.sh; sleep 60; done) &
          CLEANUP_PID=$!
          
          # Define data services to build
          DATA_SERVICES="postgres vector.db"
          
          for SERVICE in $DATA_SERVICES; do
            # Replace dots with dashes for Docker image name
            DOCKER_IMAGE_NAME=$(echo $SERVICE | tr '.' '-')
            
            echo "Building data service $SERVICE as $DOCKER_IMAGE_NAME..."
            
            if [ -f "${SERVICE}/Dockerfile" ]; then
              echo "Building $DOCKER_IMAGE_NAME directly with Docker..."
              DOCKER_BUILDKIT=1 BUILDKIT_PROGRESS=plain docker build \
                --build-arg BUILDKIT_INLINE_CACHE=1 \
                --cache-from registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${DOCKER_IMAGE_NAME}:latest \
                --cache-from registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${DOCKER_IMAGE_NAME}:${{ env.ENVIRONMENT }} \
                --platform linux/arm64 \
                -t ${DOCKER_IMAGE_NAME} \
                -f ${SERVICE}/Dockerfile \
                ./${SERVICE} || {
                  echo "⚠️ Warning: Error building $DOCKER_IMAGE_NAME with direct Docker command, but continuing"
                }
              
              # Run cleanup after each build
              /tmp/cleanup.sh
            else
              echo "No Dockerfile found for $SERVICE, skipping build"
            fi
          done
          
          # Kill cleanup process
          kill $CLEANUP_PID || true
          
      - name: Tag and push Docker images
        run: |
          SHORT_SHA=$(echo $GITHUB_SHA | cut -c1-7)
          
          # Refresh auth before pushing
          doctl registry login --expiry-seconds 3600
          
          # First process services images
          cd services
          
          # Get list of services directly from the SERVICES variable
          SERVICES="auth supertokens voyager mcp agents cron"
          
          # Override if service parameter is provided
          if [[ -n "${{ github.event.inputs.service }}" ]]; then
            SERVICES="${{ github.event.inputs.service }}"
          fi
          
          # Tag and push each service's image
          for SERVICE in $SERVICES; do
            echo "Processing image for $SERVICE..."
            
            # Check if the image exists
            if docker images $SERVICE | grep -q "$SERVICE"; then
              echo "Image found for $SERVICE, tagging and pushing..."
              
              # Create tags
              docker tag $SERVICE registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${SHORT_SHA}
              docker tag $SERVICE registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${{ env.ENVIRONMENT }}
              docker tag $SERVICE registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:latest
              
              # Push each tag
              for TAG in ${SHORT_SHA} ${{ env.ENVIRONMENT }} latest; do
                echo "Pushing ${SERVICE}:${TAG}..."
                docker push registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${TAG}
              done
            else
              echo "Warning: No image found for $SERVICE, skipping"
              docker images
            fi
          done
          
          # Now process data services images
          cd ../data
          
          # Define data services
          DATA_SERVICES="postgres vector-db"
          
          # Tag and push each data service's image
          for SERVICE in $DATA_SERVICES; do
            echo "Processing image for $SERVICE..."
            
            # Check if the image exists
            if docker images $SERVICE | grep -q "$SERVICE"; then
              echo "Image found for $SERVICE, tagging and pushing..."
              
              # Create tags
              docker tag $SERVICE registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${SHORT_SHA}
              docker tag $SERVICE registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${{ env.ENVIRONMENT }}
              docker tag $SERVICE registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:latest
              
              # Push each tag
              for TAG in ${SHORT_SHA} ${{ env.ENVIRONMENT }} latest; do
                echo "Pushing ${SERVICE}:${TAG}..."
                docker push registry.digitalocean.com/${{ secrets.DO_REGISTRY_NAME }}/${SERVICE}:${TAG}
              done
            else
              echo "Warning: No image found for $SERVICE, skipping"
              docker images
            fi
          done
          
      - name: Configure kubectl for ArgoCD sync
        run: |
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/arm64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          
          # Setup kubeconfig for DO Kubernetes
          doctl kubernetes cluster kubeconfig save ${{ secrets.DO_KUBERNETES_CLUSTER_ID }}
      
      - name: Install and configure Sealed Secrets
        run: |
          # Install kubeseal
          curl -L https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.26.0/kubeseal-0.26.0-linux-arm64.tar.gz -o kubeseal.tar.gz
          tar -xvzf kubeseal.tar.gz kubeseal
          chmod +x kubeseal
          sudo mv kubeseal /usr/local/bin/
          
          # Check if sealed-secrets namespace exists, if not create it
          if ! kubectl get namespace sealed-secrets &> /dev/null; then
            kubectl create namespace sealed-secrets
            
            # Add Helm repo
            helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets
            helm repo update
            
            # Install controller
            helm install sealed-secrets sealed-secrets/sealed-secrets -n sealed-secrets
            
            # Wait for controller to be ready
            kubectl -n sealed-secrets wait --for=condition=available deployment/sealed-secrets --timeout=90s
          fi
          
          # Create directory for certificate
          mkdir -p .sealed-secrets
          
          # Fetch certificate
          kubeseal --fetch-cert --controller-name=sealed-secrets --controller-namespace=sealed-secrets > .sealed-secrets/sealed-secrets-cert.pem
          
      - name: Generate Sealed Secrets for data services
        run: |
          cd data
          # Create temporary .env file from GitHub Secrets
          cat > .env << EOF
          # Postgres
          POSTGRES_USER=${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_DB=postgres
          POSTGRES_DB_POSEY=${{ secrets.POSTGRES_DB_POSEY }}
          POSTGRES_PORT=${{ secrets.POSTGRES_PORT || '3333' }}
          POSTGRES_HOST=${{ secrets.POSTGRES_HOST || 'posey-postgres' }}
          
          # Qdrant
          QDRANT_URL=${{ secrets.QDRANT_URL || 'http://posey-vector-db' }}
          QDRANT_PORT=${{ secrets.QDRANT_PORT || '1111' }}
          QDRANT_API_KEY=${{ secrets.QDRANT_API_KEY || '' }}
          EOF
          
          # Run the data sealed secrets generator
          cd ..
          export GITHUB_ACTIONS=true
          ./scripts/sealed-secrets/create-data-secrets.sh
          
      - name: Generate Sealed Secrets for application services
        run: |
          cd services
          # Create temporary .env file from GitHub Secrets
          cat > .env << EOF
          # Core Application Settings
          NODE_ENV=production
          ENVIRONMENT=${{ env.ENVIRONMENT }}
          
          # Service Ports & URLs
          AUTH_PORT=${{ secrets.AUTH_PORT || '9999' }}
          MCP_PORT=${{ secrets.MCP_PORT || '5050' }}
          VOYAGER_PORT=${{ secrets.VOYAGER_PORT || '7777' }}
          SUPER_TOKENS_PORT=${{ secrets.SUPER_TOKENS_PORT || '3567' }}
          
          # Auth Service
          AUTH_API_DOMAIN=${{ secrets.AUTH_API_DOMAIN || 'http://posey-auth' }}
          AUTH_BASE_URL=${{ secrets.AUTH_BASE_URL || 'http://posey-auth' }}
          UI_BASE_URL=${{ secrets.UI_BASE_URL || 'https://posey.ai' }}
          COOKIE_DOMAIN=${{ secrets.COOKIE_DOMAIN || '.posey.ai' }}
          
          # Cron Schedules
          MEMORY_PRUNING_SCHEDULE=${{ secrets.MEMORY_PRUNING_SCHEDULE || '"0 0 * * *"' }}
          MEMORY_CONSOLIDATION_SCHEDULE=${{ secrets.MEMORY_CONSOLIDATION_SCHEDULE || '"0 4 * * *"' }}
          CACHE_CLEANUP_SCHEDULE=${{ secrets.CACHE_CLEANUP_SCHEDULE || '"0 */6 * * *"' }}
          MEMORY_STATS_SCHEDULE=${{ secrets.MEMORY_STATS_SCHEDULE || '"0 1 * * *"' }}
          
          # AI Models
          EMBEDDING_MODEL=${{ secrets.EMBEDDING_MODEL || 'thenlper/gte-large' }}
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}
          
          # JWT
          JWT_SECRET_KEY=${{ secrets.JWT_SECRET_KEY }}
          
          # PostgreSQL
          POSTGRES_DB_POSEY=${{ secrets.POSTGRES_DB_POSEY || 'posey' }}
          POSTGRES_DB_SUPERTOKENS=${{ secrets.POSTGRES_DB_SUPERTOKENS || 'supertokens' }}
          POSTGRES_USER=${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_HOST=${{ secrets.POSTGRES_HOST || 'posey-postgres' }}
          POSTGRES_PORT=${{ secrets.POSTGRES_PORT || '3333' }}
          POSTGRES_DSN_POSEY=postgresql://${{ secrets.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@${{ secrets.POSTGRES_HOST || 'posey-postgres' }}:${{ secrets.POSTGRES_PORT || '3333' }}/${{ secrets.POSTGRES_DB_POSEY || 'posey' }}
          POSTGRES_DSN_SUPERTOKENS=postgresql://${{ secrets.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@${{ secrets.POSTGRES_HOST || 'posey-postgres' }}:${{ secrets.POSTGRES_PORT || '3333' }}/${{ secrets.POSTGRES_DB_SUPERTOKENS || 'supertokens' }}
          
          # Qdrant
          QDRANT_URL=${{ secrets.QDRANT_URL || 'http://posey-vector-db' }}
          QDRANT_PORT=${{ secrets.QDRANT_PORT || '1111' }}
          QDRANT_HOST=${{ secrets.QDRANT_URL || 'http://posey-vector-db' }}
          
          # SuperTokens
          SUPERTOKENS_CONNECTION_URI=${{ secrets.SUPERTOKENS_CONNECTION_URI || 'http://posey-supertokens:3567' }}
          SUPERTOKENS_API_KEY=${{ secrets.SUPERTOKENS_API_KEY }}
          
          # Other values
          VOYAGER_DOMAIN=${{ secrets.VOYAGER_DOMAIN || 'posey-voyager' }}
          EOF
          
          # Run the services sealed secrets generator
          cd ..
          export GITHUB_ACTIONS=true
          ./scripts/sealed-secrets/create-services-secrets.sh

      - name: Trigger ArgoCD sync
        if: success()
        continue-on-error: true  # Make this step optional so the workflow doesn't fail
        timeout-minutes: 5  # Increased timeout
        run: |
          # Install argocd CLI with better error handling
          echo "Downloading ArgoCD CLI..."
          mkdir -p /tmp/argocd-download
          cd /tmp/argocd-download
          
          # Try multiple times with different approaches
          if ! curl -sSL --retry 3 --retry-delay 5 -o argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-arm64; then
            echo "Direct download failed, trying with wget..."
            wget -q https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-arm64 -O argocd || {
              echo "Error downloading ArgoCD CLI. Trying specific version..."
              curl -sSL --retry 3 -o argocd https://github.com/argoproj/argo-cd/releases/download/v2.8.4/argocd-linux-arm64
            }
          fi
          
          chmod +x argocd
          sudo mv argocd /usr/local/bin/
          
          # Verify installation
          if ! argocd version --client; then
            echo "Failed to install ArgoCD CLI. Exiting."
            exit 1
          fi
          
          # Get ArgoCD password from Kubernetes secret
          ADMIN_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          
          # Login to ArgoCD with correct parameters
          echo "Logging in to ArgoCD at argo.posey.ai with grpc-web..."
          argocd login argo.posey.ai --username admin --password "$ADMIN_PASSWORD" --grpc-web
          
          # Get the short SHA for the latest commit
          SHORT_SHA=$(echo $GITHUB_SHA | cut -c1-7)
          echo "Using image tag: ${SHORT_SHA}"
          
          # Register applications if they don't exist
          echo "Checking if applications exist in ArgoCD..."
          
          # Define application details - include both services and data
          SERVICES="auth supertokens voyager mcp agents cron"
          DATA_SERVICES="postgres vector.db"
          
          if [[ -n "${{ github.event.inputs.service }}" ]]; then
            SERVICES="${{ github.event.inputs.service }}"
          fi
          
          # Create and sync service applications 
          for SERVICE in $SERVICES; do
            if ! argocd app get posey-$SERVICE &>/dev/null; then
              echo "Creating application posey-$SERVICE in ArgoCD..."
              argocd app create posey-$SERVICE \
                --repo https://github.com/${{ github.repository }}.git \
                --path services/$SERVICE/k8s \
                --dest-server https://kubernetes.default.svc \
                --dest-namespace ${{ secrets.DO_REGISTRY_NAME }} \
                --directory-recurse || true
            fi
            
            # Sync the application
            echo "Syncing posey-${SERVICE}..."
            argocd app sync posey-$SERVICE --timeout 120 --prune || true
          done
          
          # Create and sync data service applications
          for SERVICE in $DATA_SERVICES; do
            # Replace dots with dashes for app name
            APP_NAME=$(echo $SERVICE | tr '.' '-')
            
            if ! argocd app get posey-$APP_NAME &>/dev/null; then
              echo "Creating data application posey-$APP_NAME in ArgoCD..."
              argocd app create posey-$APP_NAME \
                --repo https://github.com/${{ github.repository }}.git \
                --path data/$SERVICE/k8s \
                --dest-server https://kubernetes.default.svc \
                --dest-namespace ${{ secrets.DO_REGISTRY_NAME }} \
                --directory-recurse || true
            fi
            
            # Sync the application
            echo "Syncing posey-${APP_NAME}..."
            argocd app sync posey-$APP_NAME --timeout 120 --prune || true
          done
          
          echo "ArgoCD sync completed or attempted for all services"
          
          # Apply configurations directly with kubectl as a fallback
          echo "---------------------------------------------------"
          echo "Also applying with kubectl to ensure updates..."
          cd $GITHUB_WORKSPACE
          
          # Define namespace and services
          NAMESPACE="${{ secrets.DO_REGISTRY_NAME }}"
          echo "Using namespace: ${NAMESPACE}"
          
          # Apply configurations with kubectl
          echo "Applying configurations directly with kubectl..."
          kubectl get namespace $NAMESPACE || kubectl create namespace $NAMESPACE
          
          # Apply shared resources from services
          if [ -d "services/shared/k8s" ]; then
            echo "Applying services shared resources..."
            kubectl apply -k services/shared/k8s -n $NAMESPACE || true
          fi
          
          # Apply shared resources from data
          if [ -d "data/shared/k8s" ]; then
            echo "Applying data shared resources..."
            kubectl apply -k data/shared/k8s -n $NAMESPACE || true
          fi
          
          # Apply each service's k8s files
          for SERVICE in $SERVICES; do
            if [ -d "services/$SERVICE/k8s" ]; then
              echo "Applying resources for service $SERVICE..."
              kubectl apply -k services/$SERVICE/k8s -n $NAMESPACE || true
            fi
          done
          
          # Apply each data service's k8s files
          for SERVICE in $DATA_SERVICES; do
            if [ -d "data/$SERVICE/k8s" ]; then
              echo "Applying resources for data $SERVICE..."
              kubectl apply -k data/$SERVICE/k8s -n $NAMESPACE || true
            fi
          done
          
          echo "Deployment initiated. All services should be updated in Kubernetes."
          
      - name: Create minimal .env file for CI
        run: |
          cat > services/.env << EOF
          # This is an auto-generated .env file for CI deployment
          ENVIRONMENT=${{ env.ENVIRONMENT }}
          
          # DigitalOcean configuration
          DO_REGISTRY_NAME=${{ secrets.DO_REGISTRY_NAME }}
          DO_KUBERNETES_CLUSTER_ID=${{ secrets.DO_KUBERNETES_CLUSTER_ID }}
          
          # Add other CI-specific environment variables here
          NODE_ENV=production
          LOG_LEVEL=info
          
          # Add any additional secrets that deployment scripts need
          QDRANT_HOST=${{ secrets.QDRANT_HOST || 'qdrant.default.svc.cluster.local' }}
          QDRANT_PORT=${{ secrets.QDRANT_PORT || '6333' }}
          POSTGRES_HOST=${{ secrets.POSTGRES_HOST || 'postgres.default.svc.cluster.local' }}
          POSTGRES_PORT=${{ secrets.POSTGRES_PORT || '5432' }}
          EOF
          
          echo "Created CI environment file with necessary deployment variables" 