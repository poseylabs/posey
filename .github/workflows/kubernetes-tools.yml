name: Kubernetes Cluster Tools

on:
  workflow_dispatch:
    inputs:
      cluster:
        description: 'Target Kubernetes cluster'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging
      action:
        description: 'Action to perform'
        required: true
        type: choice
        options:
          - display-status
          - update-deployments
          - cleanup-resources
          - backup-databases
          - restart-services
          - manage-ingress
      namespace:
        description: 'Kubernetes namespace'
        required: false
        default: 'posey'
        type: string
      resource_name:
        description: 'Resource name (if applicable)'
        required: false
        type: string

jobs:
  kubernetes-tools:
    name: Kubernetes Management Tools
    runs-on: ubuntu-latest
    
    env:
      CLUSTER_ID: ${{ github.event.inputs.cluster == 'production' && secrets.DO_KUBERNETES_CLUSTER_ID || secrets.DO_KUBERNETES_CLUSTER_ID_STAGING }}
      NAMESPACE: ${{ github.event.inputs.namespace || 'posey' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        
      - name: Setup Node.js
        if: github.event.inputs.action == 'restart-services'
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          
      - name: Enable Corepack
        if: github.event.inputs.action == 'restart-services'
        run: |
          corepack enable
          yarn --version
          
      - name: Install dependencies
        if: github.event.inputs.action == 'restart-services'
        run: |
          cd data
          yarn install
        
      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DO_API_TOKEN }}
          
      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'
          
      - name: Save DigitalOcean kubeconfig
        run: doctl kubernetes cluster kubeconfig save ${{ env.CLUSTER_ID }}
        
      - name: Display Cluster Status
        if: github.event.inputs.action == 'display-status'
        run: |
          echo "üìä Displaying cluster status for ${{ github.event.inputs.cluster }} cluster, namespace ${{ env.NAMESPACE }}"
          
          echo "Pods:"
          kubectl get pods -n ${{ env.NAMESPACE }} -o wide
          
          echo -e "\nDeployments:"
          kubectl get deployments -n ${{ env.NAMESPACE }}
          
          echo -e "\nStatefulSets:"
          kubectl get statefulsets -n ${{ env.NAMESPACE }}
          
          echo -e "\nServices:"
          kubectl get services -n ${{ env.NAMESPACE }}
          
          echo -e "\nPersistent Volume Claims:"
          kubectl get pvc -n ${{ env.NAMESPACE }}
          
          echo -e "\nIngress Resources:"
          kubectl get ingress -n ${{ env.NAMESPACE }}
          
          echo -e "\nIngress Controller Status:"
          kubectl get pods -n ingress-nginx
          kubectl get svc -n ingress-nginx
          
          echo -e "\nCluster Events (last 10):"
          kubectl get events -n ${{ env.NAMESPACE }} --sort-by=.metadata.creationTimestamp | tail -10
          
      - name: Update Deployments
        if: github.event.inputs.action == 'update-deployments'
        run: |
          if [[ -n "${{ github.event.inputs.resource_name }}" ]]; then
            echo "üîÑ Restarting deployment ${{ github.event.inputs.resource_name }} in namespace ${{ env.NAMESPACE }}"
            kubectl rollout restart deployment/${{ github.event.inputs.resource_name }} -n ${{ env.NAMESPACE }}
          else
            echo "üîÑ Restarting all deployments in namespace ${{ env.NAMESPACE }}"
            kubectl get deployments -n ${{ env.NAMESPACE }} -o name | xargs -I{} kubectl rollout restart {} -n ${{ env.NAMESPACE }}
          fi
          
          echo "üîÑ Checking rollout status..."
          kubectl get deployments -n ${{ env.NAMESPACE }} -o name | xargs -I{} kubectl rollout status {} -n ${{ env.NAMESPACE }} --timeout=300s
          
      - name: Restart Services
        if: github.event.inputs.action == 'restart-services'
        run: |
          cd data
          
          if [[ -n "${{ github.event.inputs.resource_name }}" ]]; then
            echo "üîÑ Redeploying service ${{ github.event.inputs.resource_name }} in namespace ${{ env.NAMESPACE }}"
            
            # Override to use the specified namespace
            export KUBE_NAMESPACE=${{ env.NAMESPACE }}
            
            # Deploy specific service
            yarn deploy ${{ github.event.inputs.resource_name }} ${{ github.event.inputs.cluster == 'staging' && '--staging' || '' }}
          else
            echo "üîÑ Redeploying all services in namespace ${{ env.NAMESPACE }}"
            
            # Override to use the specified namespace
            export KUBE_NAMESPACE=${{ env.NAMESPACE }}
            
            # Deploy all services
            yarn deploy ${{ github.event.inputs.cluster == 'staging' && '--staging' || '' }}
          fi
          
      - name: Manage Ingress
        if: github.event.inputs.action == 'manage-ingress'
        run: |
          echo "üîÑ Managing Ingress Resources for namespace ${{ env.NAMESPACE }}"
          
          # Display current ingress status
          echo "Current Ingress Resources:"
          kubectl get ingress -n ${{ env.NAMESPACE }}
          
          echo "Current Ingress Controller Status:"
          kubectl get pods -n ingress-nginx
          kubectl get svc -n ingress-nginx
          
          # Verify if NGINX Ingress Controller is installed
          if ! kubectl get ns ingress-nginx > /dev/null 2>&1; then
            echo "‚ö†Ô∏è NGINX Ingress Controller is not installed"
            echo "Installing NGINX Ingress Controller..."
            kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/do/deploy.yaml
          else
            echo "‚úÖ NGINX Ingress Controller is already installed"
          fi
          
          # Verify if cert-manager is installed (for TLS)
          if ! kubectl get ns cert-manager > /dev/null 2>&1; then
            echo "‚ö†Ô∏è cert-manager is not installed (required for HTTPS)"
            echo "To install cert-manager, use the deploy-ingress workflow"
          else
            echo "‚úÖ cert-manager is already installed"
            echo "TLS Certificates status:"
            kubectl get certificates -n ${{ env.NAMESPACE }}
            kubectl get certificaterequests -n ${{ env.NAMESPACE }}
          fi
          
          echo ""
          echo "To update ingress configuration, use the deploy-ingress workflow"
          
      - name: Cleanup Resources
        if: github.event.inputs.action == 'cleanup-resources'
        run: |
          echo "üßπ Cleaning up resources in ${{ github.event.inputs.cluster }} cluster, namespace ${{ env.NAMESPACE }}"
          
          # Remove failed pods
          echo "Removing failed pods..."
          kubectl get pods -n ${{ env.NAMESPACE }} | grep -E 'Error|CrashLoopBackOff' | awk '{print $1}' | xargs -r kubectl delete pod -n ${{ env.NAMESPACE }}
          
          # Remove completed jobs
          echo "Removing completed jobs..."
          kubectl get jobs -n ${{ env.NAMESPACE }} -o name | xargs -r -I{} kubectl delete {} -n ${{ env.NAMESPACE }}
          
          # Clear terminating pods (if stuck)
          echo "Checking for stuck terminating pods..."
          terminating_pods=$(kubectl get pods -n ${{ env.NAMESPACE }} | grep Terminating | awk '{print $1}')
          if [[ -n "$terminating_pods" ]]; then
            echo "Found terminating pods, force removing them..."
            echo "$terminating_pods" | xargs -r -I{} kubectl delete pod {} -n ${{ env.NAMESPACE }} --force --grace-period=0
          else
            echo "No stuck terminating pods found."
          fi
          
          echo "‚úÖ Cleanup completed"
          
      - name: Backup Databases
        if: github.event.inputs.action == 'backup-databases'
        run: |
          echo "üíæ Starting database backups for ${{ github.event.inputs.cluster }} cluster, namespace ${{ env.NAMESPACE }}"
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Create a job for Postgres backup
          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: postgres-backup-$TIMESTAMP
            namespace: ${{ env.NAMESPACE }}
          spec:
            ttlSecondsAfterFinished: 86400
            template:
              spec:
                containers:
                - name: postgres-backup
                  image: postgres:13
                  command:
                  - /bin/bash
                  - -c
                  - |
                    pg_dump -h posey-postgres -U ${{ secrets.POSTGRES_USER }} -d ${{ secrets.POSTGRES_DB_POSEY }} -p ${{ secrets.POSTGRES_PORT }} -F c -f /tmp/backup.dump
                    echo "Backup completed at \$(date)"
                    sleep 60
                  env:
                  - name: PGPASSWORD
                    value: ${{ secrets.POSTGRES_PASSWORD }}
                restartPolicy: Never
          EOF
          
          # Create a job for Couchbase backup
          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: couchbase-backup-$TIMESTAMP
            namespace: ${{ env.NAMESPACE }}
          spec:
            ttlSecondsAfterFinished: 86400
            template:
              spec:
                containers:
                - name: couchbase-backup
                  image: couchbase:community-7.1.1
                  command:
                  - /bin/bash
                  - -c
                  - |
                    mkdir -p /tmp/backup
                    cbbackup http://posey-couchbase:8091 /tmp/backup -u ${{ secrets.COUCHBASE_USER }} -p ${{ secrets.COUCHBASE_PASSWORD }} -b ${{ secrets.COUCHBASE_BUCKET }}
                    echo "Backup completed at \$(date)"
                    sleep 60
                restartPolicy: Never
          EOF
          
          echo "‚úÖ Backup jobs created. Check job status with:"
          echo "kubectl get jobs -n ${{ env.NAMESPACE }}" 